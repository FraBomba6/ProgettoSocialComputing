{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import networkx.readwrite.gpickle as pkl\n",
    "import networkx as nx\n",
    "from pyvis.network import Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup credentials\n",
    "\n",
    "import keys\n",
    "\n",
    "consumer_key = keys.key\n",
    "consumer_secret = keys.secret\n",
    "bearer_token = keys.bearer\n",
    "access_token = keys.access_token\n",
    "access_secret = keys.access_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Authentication on Twitter API\n",
    "\n",
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "if api.verify_credentials:\n",
    "    print(\"Auth completed successfuly!\")\n",
    "else:\n",
    "    print(\"Issue occoured during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import serializer from an external module\n",
    "\n",
    "from serializer import Serializer\n",
    "\n",
    "# Define data directory\n",
    "dataDir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get starting users info\n",
    "accounts = [\"mizzaro\", \"damiano10\", \"Miccighel_\", \"eglu81\", \"KevinRoitero\"]\n",
    "for account in accounts:\n",
    "    serializer = Serializer(f'{dataDir}/{account}')\n",
    "    profile = api.get_user(account)\n",
    "    profile_json = profile._json\n",
    "    serializer.serialize_json(f'{account}_profile.json', profile_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #1 of the assignment: retrieve starting users followers and followings\n",
    "\n",
    "for account in accounts:\n",
    "    print(f\"Processing @{account}\")\n",
    "    serializer = Serializer(f'{dataDir}/{account}')\n",
    "\n",
    "### FOLLOWERS\n",
    "\n",
    "    account_followers = []\n",
    "    for item in tweepy.Cursor(\n",
    "            api.followers,\n",
    "            screen_name=account,\n",
    "            skip_status=True,\n",
    "            include_user_entities=False\n",
    "    ).items():\n",
    "        found_follower = item._json\n",
    "        account_followers.append(found_follower)\n",
    "\n",
    "    print(f\"Found {len(account_followers)} followers for @{account}\")\n",
    "    serializer.serialize_json(f\"{account}_follower.json\", account_followers)\n",
    "\n",
    "### FOLLOWINGS\n",
    "\n",
    "    account_followings = []\n",
    "    for item in tweepy.Cursor(\n",
    "            api.friends,\n",
    "            screen_name=account,\n",
    "            skip_status=True,\n",
    "            include_user_entities=False\n",
    "    ).items():\n",
    "        found_followings = item._json\n",
    "        account_followings.append(found_followings)\n",
    "\n",
    "    print(f\"@{account} follows {len(account_followings)} users\")\n",
    "    serializer.serialize_json(f\"{account}_following.json\", account_followings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Points #2 and #3 of the assignment: pick 5 random followers of the starting users,\n",
    "# retrieve 10 followers each, pick 5 random followings of the starting users\n",
    "# and retrieve 10 followings each\n",
    "import random\n",
    "\n",
    "for account in accounts:\n",
    "    serializer = Serializer(f'{dataDir}/{account}')\n",
    "    json = serializer.read_json(f\"{account}_follower.json\")\n",
    "    for count in range(0, 5):\n",
    "        random_follower = random.choice(json)\n",
    "        random_follower_screenName = random_follower[\"screen_name\"]\n",
    "        random_follower_id = random_follower[\"id\"]\n",
    "        random_follower_followers = []\n",
    "        for item in tweepy.Cursor(\n",
    "                api.followers,\n",
    "                screen_name=random_follower_screenName,\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "            found_follower = item._json\n",
    "            random_follower_followers.append(found_follower)\n",
    "        print(f\"Found {len(random_follower_followers)} followers for @{random_follower_screenName}\")\n",
    "        serializer.serialize_json(f\"random_{random_follower_id}_follower.json\", random_follower_followers)\n",
    "\n",
    "    json = serializer.read_json(f\"{account}_following.json\")\n",
    "    for count in range(0, 5):\n",
    "        random_following = random.choice(json)\n",
    "        random_following_screenName = random_following[\"screen_name\"]\n",
    "        random_following_id = random_following[\"id\"]\n",
    "        random_following_followings = []\n",
    "        for item in tweepy.Cursor(\n",
    "                api.friends,\n",
    "                screen_name=random_following_screenName,\n",
    "                skip_status=True,\n",
    "                include_user_entities=False\n",
    "        ).items(10):\n",
    "            found_friend = item._json\n",
    "            random_following_followings.append(found_friend)\n",
    "        print(f\"@{random_following_screenName} follows {len(random_following_followings)} users\")\n",
    "        serializer.serialize_json(f\"random_{random_following_id}_following.json\", random_following_followings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #4 of the assignment: retrieve all encountered users' profile\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "error_count = 0         # Keep trace of how many errors occurred during user retrieval (account not found)\n",
    "duplicate_count = 0     # Keep trace of users already encountered\n",
    "\n",
    "all_users = []\n",
    "processed_ids = []\n",
    "\n",
    "print(f\"Start at {datetime.now()}\")\n",
    "for account in accounts:\n",
    "    print(\n",
    "        f'\\n\\n*************************************\\nProcessing {account} and his friends\\n*************************************')\n",
    "    serializer = Serializer(f'{dataDir}/{account}')\n",
    "    with os.scandir(f'{dataDir}/{account}') as it:\n",
    "        for entry in it:\n",
    "            if entry.name.startswith('random') and not entry.name.endswith('profile.json'):\n",
    "                print('\\n\\n******************')\n",
    "                users_data = serializer.read_json(f\"{entry.name}\")\n",
    "                print(f'\\nProcessing {entry.name}, containing {len(users_data)} users\\n******************\\n\\n')\n",
    "                for user in users_data:\n",
    "                    if user[\"id\"] not in processed_ids:\n",
    "                        try:\n",
    "                            print(f'Processing {user[\"id\"]}, user #{len(all_users) + 1}')\n",
    "                            user_details = api.get_user(user[\"id\"])._json\n",
    "                            useful_user_details = {\n",
    "                                \"id\": user_details[\"id\"],\n",
    "                                \"name\": user_details[\"name\"],\n",
    "                                \"screen_name\": user_details[\"screen_name\"],\n",
    "                                \"description\": user_details[\"description\"],\n",
    "                                \"followers_count\": user_details[\"followers_count\"],\n",
    "                                \"friends_count\": user_details[\"friends_count\"],\n",
    "                                \"profile_image_url_https\": user_details[\"profile_image_url_https\"]\n",
    "                            }\n",
    "                            all_users.append(useful_user_details)\n",
    "                            processed_ids.append(user_details[\"id\"])\n",
    "                        except tweepy.TweepError:\n",
    "                            error_count += 1\n",
    "                            print(\"Skipped user because of error\")\n",
    "                    else:\n",
    "                        duplicate_count += 1\n",
    "serializer = Serializer(dataDir)\n",
    "print('\\n\\n*************************************\\n')\n",
    "serializer.serialize_json(\"all_users.json\", all_users)\n",
    "print('\\n*************************************\\n\\n')\n",
    "print(f'Found {error_count} errors and {duplicate_count} duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# As requested, before building the social network is necessary to check friendships\n",
    "\n",
    "def get_friendship(sourceid, targetid, api):\n",
    "    kind = \"\"\n",
    "\n",
    "    friendship = api.show_friendship(source_id=sourceid, target_id=targetid)\n",
    "\n",
    "    if not friendship[0].following and not friendship[0].followed_by:\n",
    "        kind = \"none\"\n",
    "    elif not friendship[0].following and friendship[0].followed_by:\n",
    "        kind = \"r_l\"\n",
    "    elif friendship[0].following and not friendship[0].followed_by:\n",
    "        kind = \"l_r\"\n",
    "    else:\n",
    "        kind = \"bi\"\n",
    "\n",
    "    return {\n",
    "        \"source_id\": sourceid,\n",
    "        \"target_id\": targetid,\n",
    "        \"friendship\": kind\n",
    "    }\n",
    "\n",
    "serializer = Serializer(dataDir)\n",
    "users = serializer.read_json(\"all_users.json\")\n",
    "edges = []\n",
    "count = 0\n",
    "for account in accounts:\n",
    "    serializer = Serializer(f'{dataDir}/{account}')\n",
    "    account_json = serializer.read_json(f\"{account}_profile.json\")\n",
    "    account_id = account_json[\"id\"]\n",
    "    for user in users:\n",
    "        if user[\"id\"] is not account_id:\n",
    "            edges.append(get_friendship(account_id, user[\"id\"], api))\n",
    "            count += 1\n",
    "            print(f\"Added friendship between {account} and {user['screen_name']} #{count}\")\n",
    "    # There's also the necessity to check friendships between the random picked users at Point #2 and #3 and their followers and followings\n",
    "    with os.scandir(f'{dataDir}/{account}') as it:\n",
    "        for entry in it:\n",
    "            if entry.name.endswith('.json') and entry.name.startswith('random'):\n",
    "                fileId = int(entry.name.split(\"_\")[1])\n",
    "                json = serializer.read_json(entry.name)\n",
    "                for profile in json:\n",
    "                    edges.append(get_friendship(fileId, profile[\"id\"], api))\n",
    "                    count += 1\n",
    "                    print(f\"Added friendship between {fileId} and {profile['screen_name']} #{count}\")\n",
    "\n",
    "serializer = Serializer(dataDir)\n",
    "serializer.serialize_json(f'all_friendships.json', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #5 of the assignment: build the social network\n",
    "def buildFromJson(path, nodeJson, edgeJson):\n",
    "    # Create base diGraph\n",
    "    diGraph = nx.DiGraph(students=[\"Lorenzo Bellina\" \"Francesco Bombassei De Bona\", \"Andrea Cantarutti\", \"Gabriele Dominici\"])\n",
    "\n",
    "    serializer = Serializer(path)\n",
    "\n",
    "    # Read users from json and add them to the diGraph\n",
    "    all_nodes = serializer.read_json(nodeJson)\n",
    "    for profile in all_nodes:\n",
    "        diGraph.add_node(profile[\"id\"], follower_ing = 0, following_ing = 0, **profile)\n",
    "\n",
    "    # Read friendships from json and add them to the diGraph\n",
    "    all_edges = serializer.read_json(edgeJson)\n",
    "    for friendship in all_edges:\n",
    "        if friendship[\"friendship\"] != \"none\":\n",
    "            if friendship[\"friendship\"] == \"bi\":\n",
    "                diGraph.add_edge(friendship[\"source_id\"], friendship[\"target_id\"], type = friendship[\"friendship\"])\n",
    "                diGraph.add_edge(friendship[\"target_id\"], friendship[\"source_id\"], type = friendship[\"friendship\"])\n",
    "                print(f'Added bidirectional edge between {friendship[\"source_id\"]} and {friendship[\"target_id\"]}')\n",
    "            elif friendship[\"friendship\"] == \"r_l\":\n",
    "                diGraph.add_edge(friendship[\"target_id\"], friendship[\"source_id\"], type = friendship[\"friendship\"])\n",
    "                print(f'Added edge from {friendship[\"target_id\"]} to {friendship[\"source_id\"]}')\n",
    "            elif friendship[\"friendship\"] == \"l_r\":\n",
    "                diGraph.add_edge(friendship[\"source_id\"], friendship[\"target_id\"], type = friendship[\"friendship\"])\n",
    "                print(f'Added edge from {friendship[\"source_id\"]} to {friendship[\"target_id\"]}')\n",
    "\n",
    "    # Set new attributes for every node to represent number of followers and followings\n",
    "    for degree in diGraph.in_degree:\n",
    "        diGraph.nodes[degree[0]][\"follower_ing\"] = degree[1]\n",
    "    for degree in diGraph.out_degree:\n",
    "        diGraph.nodes[degree[0]][\"following_ing\"] = degree[1]\n",
    "\n",
    "    return diGraph\n",
    "\n",
    "\n",
    "diGraph = buildFromJson('data', 'all_users.json', 'all_friendships.json')\n",
    "# Save the diGraph\n",
    "nx.write_gpickle(diGraph, \"graph/diGraph_networkx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph drawn\n",
      "Graph saved to destination\n"
     ]
    }
   ],
   "source": [
    "# Point #6 of the assignment: visualize the diGraph created before\n",
    "def plotGraph(pklPath: str, isDirected: bool):\n",
    "    import random\n",
    "    r = lambda : random.randint(0, 255)\n",
    "\n",
    "    # Load the diGraph\n",
    "    twitter = pkl.read_gpickle(pklPath)\n",
    "\n",
    "    # Setup network\n",
    "    nt = Network(height=\"100%\", width=\"100%\", bgcolor=\"#111111\", directed=isDirected, font_color=\"white\", heading=\"Twitter Graph - Final Edition\")\n",
    "\n",
    "    # Model particles physic\n",
    "    nt.barnes_hut()\n",
    "\n",
    "    # Convert from NetworkX\n",
    "    nt.from_nx(twitter)\n",
    "\n",
    "    # Retrieve nodes weight\n",
    "    neighbor_map = nt.get_adj_list()\n",
    "\n",
    "    profs = [\"Miccighel_\", \"mizzaro\", \"damiano10\", \"eglu81\", \"KevinRoitero\"]\n",
    "\n",
    "    colors = {}\n",
    "\n",
    "    # Building nodes\n",
    "    for node in nt.nodes:\n",
    "        info = \"nome utente: \" + node['screen_name'] + \"<br>\" + \"id: \" + str(node['id'])\n",
    "        map_length = len(neighbor_map[node[\"id\"]])\n",
    "        node['title'] = info\n",
    "        node['label'] = node['name']\n",
    "        color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "        colors[node[\"id\"]] = color\n",
    "        if node['screen_name'] in profs:\n",
    "            node['shape'] = 'circularImage'\n",
    "            node['image'] = node['profile_image_url_https']\n",
    "        else:\n",
    "            node['color'] = color\n",
    "        node['size'] = map_length\n",
    "        node['mass'] = map_length\n",
    "\n",
    "\n",
    "    # Edges color\n",
    "    for edge in nt.edges:\n",
    "        color = colors[edge['from']]\n",
    "        edge['color'] = color\n",
    "\n",
    "    nt.toggle_hide_edges_on_drag(True)\n",
    "\n",
    "    print('Graph drawn')\n",
    "    return nt\n",
    "\n",
    "diGraphPlot = plotGraph(\"graph/diGraph_networkx.pkl\", True)\n",
    "# Save and show network\n",
    "diGraphPlot.save_graph(\"graph/diGraph.html\")\n",
    "print('Graph saved to destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To study various properties of the graph is recommended to convert the directed graph in an undirected graph\n",
    "\n",
    "graph = diGraph.to_undirected()\n",
    "nx.write_gpickle(graph, \"graph/graph_networkx.pkl\")\n",
    "graphPlot = plotGraph(\"graph/graph_networkx.pkl\", False)\n",
    "graphPlot.save_graph(\"graph/graph.html\")\n",
    "print('Graph saved to destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #7 of the assignment\n",
    "\n",
    "# Is graph connected?\n",
    "connected = nx.is_connected(graph)\n",
    "if connected:\n",
    "    print(\"The graph IS connected\")\n",
    "else:\n",
    "    print(\"The graph IS NOT connected\")\n",
    "\n",
    "# Is graph bipartite?\n",
    "bipartite = nx.is_bipartite(graph)\n",
    "if bipartite:\n",
    "    print(\"The graph IS bipartite\")\n",
    "else:\n",
    "    print(\"The graph IS NOT bipartite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #8 of the assignment: find center, diameter and radius\n",
    "\n",
    "# Center\n",
    "center = nx.center(graph)\n",
    "string = \"\"\n",
    "string += (\"Center of the graph is \" + str(center) + \" ---> [\")\n",
    "for id in center:\n",
    "    string += (graph.nodes[id][\"screen_name\"] + \", \")\n",
    "string = string[0:-2]\n",
    "string += \"]\"\n",
    "print(string)\n",
    "\n",
    "# Diameter\n",
    "diameter = nx.diameter(graph)\n",
    "print(f\"Diameter = {diameter}\")\n",
    "\n",
    "# Radius\n",
    "radius = nx.radius(graph)\n",
    "print(f\"Radius = {radius}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #9 of the assignment: find various centrality measures\n",
    "\n",
    "# !! The following properties will be printed only if NOT equals to zero !!\n",
    "# It's possible to calculate some centrality values on the undirected graph\n",
    "bt_centrality = nx.betweenness_centrality(graph)\n",
    "print(f\"Betweenness centrality:\")\n",
    "for key, value in bt_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "cl_centrality = nx.closeness_centrality(graph)\n",
    "print(f\"\\n\\nCloseness centrality:\")\n",
    "for key, value in cl_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "dg_centrality = nx.degree_centrality(graph)\n",
    "print(f\"\\n\\nDegree centrality:\")\n",
    "for key, value in dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "# Passing to the previously created directed graph is possible to calculate some more properties\n",
    "in_dg_centrality = nx.in_degree_centrality(diGraph)\n",
    "print(f\"\\n\\nIn-degree centrality:\")\n",
    "for key, value in in_dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "out_dg_centrality = nx.out_degree_centrality(diGraph)\n",
    "print(f\"\\n\\nOut-degree centrality:\")\n",
    "for key, value in out_dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "pageRank = nx.pagerank(diGraph)\n",
    "print(f\"\\n\\nPage Rank:\")\n",
    "for key, value in pageRank.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "hits = nx.hits(diGraph, max_iter=500)\n",
    "print(\"HITS:\")\n",
    "for node, authValue in hits[0].items():\n",
    "    print(f\"\\n\\t{node}\\n\\t\\tauth = {authValue}\\n\\t\\t hub = {hits[1][node]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To improve data visualization for each node, we decided to insert previous properties as node attributes\n",
    "for id in graph.nodes():\n",
    "    node = graph.nodes[id]\n",
    "    node['bt_centrality'] = bt_centrality[id]\n",
    "    node['cl_centrality'] = cl_centrality[id]\n",
    "    node['dg_centrality'] = dg_centrality[id]\n",
    "    for index, value in enumerate(graphPlot.node_ids):\n",
    "        if  value == id:\n",
    "            break\n",
    "    plotNode = graphPlot.nodes[index]\n",
    "    plotNode['bt_centrality'] = bt_centrality[id]\n",
    "    plotNode['cl_centrality'] = cl_centrality[id]\n",
    "    plotNode['dg_centrality'] = dg_centrality[id]\n",
    "    info = plotNode['title']\n",
    "    toAppend = \"<br>Betweenness centrality: \" + str(plotNode['bt_centrality']) + \"<br>Closeness centrality: \" + str(plotNode['cl_centrality']) + \"<br>Degree centrality: \" + str(plotNode['dg_centrality'])\n",
    "    info += toAppend\n",
    "    plotNode['title'] = info\n",
    "print('Added betweenness centrality, closeness centrality and degree centrality for each node in the undirected graph')\n",
    "graphPlot.save_graph(\"graph/graph.html\")\n",
    "\n",
    "for id in diGraph.nodes():\n",
    "    node = diGraph.nodes[id]\n",
    "    node['in_dg_centrality'] = in_dg_centrality[id]\n",
    "    node['out_dg_centrality'] = out_dg_centrality[id]\n",
    "    node['pageRank'] = pageRank[id]\n",
    "    node['hits_auth'] = hits[0][id]\n",
    "    node['hits_hub'] = hits[1][id]\n",
    "    for index, value in enumerate(diGraphPlot.node_ids):\n",
    "        if  value == id:\n",
    "            break\n",
    "    plotNode = diGraphPlot.nodes[index]\n",
    "    plotNode['in_dg_centrality'] = in_dg_centrality[id]\n",
    "    plotNode['out_dg_centrality'] = out_dg_centrality[id]\n",
    "    plotNode['pageRank'] = pageRank[id]\n",
    "    plotNode['hits_auth'] = hits[0][id]\n",
    "    plotNode['hits_hub'] = hits[1][id]\n",
    "    info = plotNode['title']\n",
    "    toAppend = \"<br>In-degree centrality: \" + str(plotNode['in_dg_centrality']) + \"<br>Out-degree centrality: \" + str(plotNode['out_dg_centrality']) + \"<br>PageRank: \" + str(plotNode['pageRank']) + \"<br>HITS_Auth: \" + str(plotNode['hits_auth']) + \"<br>HITS_Hub: \" + str(plotNode['hits_hub'])\n",
    "    info += toAppend\n",
    "    plotNode['title'] = info\n",
    "print('Added in-degree centrality, out-degree centrality, PageRank and HITS for each node in the directed graph')\n",
    "diGraphPlot.save_graph(\"graph/diGraph.html\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Point #10 of the assignment: generate damiano10 subgraph\n",
    "diGraph = pkl.read_gpickle(\"graph/diGraph_networkx.pkl\")\n",
    "d10_reduced_graph = nx.ego_graph(diGraph, 132646210 , radius=1, center=True)\n",
    "pkl.write_gpickle(d10_reduced_graph, 'graph/reducedGraph_networkx.pkl')\n",
    "\n",
    "d10_reduced_graphPlot = plotGraph('graph/reducedGraph_networkx.pkl', True)\n",
    "d10_reduced_graphPlot.save_graph(\"graph/reducedGraph.html\")\n",
    "\n",
    "import networkx.algorithms.approximation as alg\n",
    "\n",
    "max_clique = alg.max_clique(d10_reduced_graph.to_undirected())\n",
    "string = \"\"\n",
    "for id in max_clique:\n",
    "    string += (d10_reduced_graph.nodes[id]['screen_name'] + \", \")\n",
    "string = string[0:-2]\n",
    "print(f'Max clique: {max_clique} -----> [{string}]')\n",
    "large_clique_size = alg.large_clique_size(d10_reduced_graph.to_undirected())\n",
    "print(f'Large clique size: {large_clique_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point #11 of the assignment: generate the minimum edge cover of the graph\n",
    "\n",
    "min_edge_cover = nx.min_edge_cover(graph)\n",
    "\n",
    "min_tree_cover = nx.from_edgelist(min_edge_cover)\n",
    "pkl.write_gpickle(min_tree_cover, 'graph/min_tree_cover.pkl')\n",
    "\n",
    "def lightPlotGraph(pklPath):\n",
    "    import random\n",
    "    r = lambda : random.randint(0, 255)\n",
    "\n",
    "    # Load the diGraph\n",
    "    twitter = pkl.read_gpickle(pklPath)\n",
    "\n",
    "    # Setup network\n",
    "    nt = Network(height=\"100%\", width=\"100%\", bgcolor=\"#111111\", directed=True, font_color=\"white\", heading=\"Twitter Graph - Final Edition\")\n",
    "\n",
    "    # Model particles physic\n",
    "    nt.barnes_hut()\n",
    "\n",
    "    # Convert from NetworkX\n",
    "    nt.from_nx(twitter)\n",
    "\n",
    "    # Retrieve nodes weight\n",
    "    neighbor_map = nt.get_adj_list()\n",
    "\n",
    "    profs = [\"Miccighel_\", \"mizzaro\", \"damiano10\", \"eglu81\", \"KevinRoitero\"]\n",
    "\n",
    "    colors = {}\n",
    "\n",
    "    # Building nodes\n",
    "    for node in nt.nodes:\n",
    "        map_length = len(neighbor_map[node[\"id\"]])\n",
    "        color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "        colors[node[\"id\"]] = color\n",
    "        node['color'] = color\n",
    "        node['size'] = map_length\n",
    "\n",
    "\n",
    "    # Edges color\n",
    "    for edge in nt.edges:\n",
    "        color = colors[edge['from']]\n",
    "        edge['color'] = color\n",
    "\n",
    "    return nt\n",
    "\n",
    "\n",
    "nt = lightPlotGraph('graph/min_tree_cover.pkl')\n",
    "# Save and show network\n",
    "nt.save_graph(\"graph/min_tree_cover.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Point #12 of the assignment: calculate omega and sigma of the graph\n",
    "\n",
    "omega = nx.omega(graph, niter=10, nrand=2)\n",
    "print(f'Omega value: {omega}')\n",
    "\n",
    "sigma = nx.sigma(graph, niter=10, nrand=2)\n",
    "print(f'Sigma value: {sigma}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Point #13 of the assignment: calculate Pearson and Kendall correlation coefficient of centrality measures\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "measures = {\"bt_centrality\": bt_centrality, \"cl_centrality\": cl_centrality, \"dg_centrality\": dg_centrality,\n",
    "            \"in_dg_centrality\": in_dg_centrality, \"out_dg_centrality\": out_dg_centrality,\n",
    "            \"pageRank\": pageRank, \"hits-hub\":hits[0], \"hits-auth\":hits[1]}\n",
    "results = {}\n",
    "for i in measures.keys():\n",
    "    for j in measures.keys():\n",
    "        if i != j:\n",
    "            results[f\"pearson-{i}-{j}\"], _ = pearsonr(list(measures[i].values()), list(measures[j].values()))\n",
    "            results[f\"kendall-{i}-{j}\"], _ = kendalltau(list(measures[i].values()), list(measures[j].values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "key = measures.keys()\n",
    "matrix1 = [[0 for i in key] for j in key]\n",
    "matrix2 = [[0 for i in key] for j in key]\n",
    "\n",
    "for index, i in enumerate(key):\n",
    "    for index2, j in enumerate(key):\n",
    "        if i == j:\n",
    "            matrix1[index][index2] = 0\n",
    "            matrix2[index][index2] = 0\n",
    "        else:\n",
    "            matrix1[index][index2] = results[f\"pearson-{i}-{j}\"]\n",
    "            matrix2[index][index2] = results[f\"kendall-{i}-{j}\"]\n",
    "\n",
    "df1 = pd.DataFrame(matrix1)\n",
    "df1.columns = key\n",
    "df1.index = key\n",
    "            \n",
    "fig1 =px.imshow(df1, title=\"Pearson\")\n",
    "fig1.show()\n",
    "fig1.write_image(\"graph/figRho.png\")\n",
    "\n",
    "df2 = pd.DataFrame(matrix2)\n",
    "df2.columns = key\n",
    "df2.index = key\n",
    "\n",
    "fig2 =px.imshow(df2, title=\"Kendall\")\n",
    "fig2.show()\n",
    "fig2.write_image(\"graph/figTau.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We decided then to analyze the whole network without any limit\n",
    "\n",
    "# To ensure that we were using the maximum Twitter API capabilities we utilized both User authentication and App authentication\n",
    "# For user auth:\n",
    "#   auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#   auth.set_access_token(access_token, access_secret)\n",
    "# For app auth:\n",
    "#   auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# Then, using followers_ids, friends_ids and show_friendship we obtained all edges\n",
    "\n",
    "\n",
    "# THE FOLLOWING CODE IS JUST FOR EXAMPLE\n",
    "# We started from splitting the ids to which apply friends_ids/followers_ids and to which apply show_friendship\n",
    "users = serializer.read_json(\"all_users.json\")\n",
    "threshold = 50000\n",
    "for_showFriendships = []\n",
    "for_ids = []\n",
    "for user in users:\n",
    "    if user['followers_count'] > threshold or user['friends_count'] > threshold:\n",
    "        for_showFriendships.append(user['id'])\n",
    "    else:\n",
    "        for_ids.append(user['id'])\n",
    "\n",
    "# We then obtained all the ids and relationships we need executing the following scripts\n",
    "\n",
    "for user in for_ids:\n",
    "    try:\n",
    "        followers = []\n",
    "        for item in tweepy.Cursor(\n",
    "                api.followers_ids,\n",
    "                id=user\n",
    "        ).items():\n",
    "            if item in users:\n",
    "                followers.append(item)\n",
    "        serializer.serialize_json(f'{user}_followers_ids.json', followers)\n",
    "    except tweepy.TweepError:\n",
    "        print(\"Error occurred, skipping\")\n",
    "    try:\n",
    "        friends = []\n",
    "        for item in tweepy.Cursor(\n",
    "                api.friends_ids,\n",
    "                id=user\n",
    "        ).items():\n",
    "            if item in users:\n",
    "                friends.append(item)\n",
    "        serializer.serialize_json(f'{user}_followings_ids.json', friends)\n",
    "    except tweepy.TweepError:\n",
    "        print(\"Error occurred, skipping\")\n",
    "\n",
    "count = 0\n",
    "for source in for_showFriendships:\n",
    "    count += 1\n",
    "    friendships = []\n",
    "    for i in range(count, len(for_showFriendships)):\n",
    "        target = for_showFriendships[i]\n",
    "        try:\n",
    "            friendships.append(get_friendship(source, target, api)) # We defined a function that build a dict based on the result from show_friendship\n",
    "        except tweepy.TweepError:\n",
    "            print(\"Error occurred, skipping\")\n",
    "        serializer.serialize_json(f'found_missing.json', friendships)\n",
    "\n",
    "# Finally we merged the new acquired edges into the previous\n",
    "# To improve our results we decided to enrich the starting graph\n",
    "betterGraph = buildFromJson('data', 'all_users.json', 'complete_friendships.json')\n",
    "pkl.write_gpickle(betterGraph, \"graph/better_networkx.pkl\")\n",
    "betterGraphPlot = plotGraph(\"graph/better_networkx.pkl\", True)\n",
    "betterGraphPlot.save_graph(\"graph/betterGraph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-3f31a08e814e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0md10_reduced_betterGraph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mego_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbetterGraph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m132646210\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mradius\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcenter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mpkl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite_gpickle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md10_reduced_betterGraph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'graph/reducedBetterGraph_networkx.pkl'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mnt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplotGraph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'graph/reducedBetterGraph_networkx.pkl'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mnt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"graph/reducedBetterGraph.html\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plotGraph' is not defined"
     ]
    }
   ],
   "source": [
    "# We also created a more realistic version of the damiano10 subgraph\n",
    "betterGraph = pkl.read_gpickle(\"graph/better_networkx.pkl\")\n",
    "d10_reduced_betterGraph = nx.ego_graph(betterGraph, 132646210 , radius=1, center=True)\n",
    "pkl.write_gpickle(d10_reduced_betterGraph, 'graph/reducedBetterGraph_networkx.pkl')\n",
    "nt = plotGraph('graph/reducedBetterGraph_networkx.pkl', True)\n",
    "nt.save_graph(\"graph/reducedBetterGraph.html\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Then, we decided to recalculate some properties even on betterGraph\n",
    "# We started from converting the graph to undirected\n",
    "undiBetterGraph = betterGraph.to_undirected()\n",
    "\n",
    "# Is graph connected?\n",
    "connected = nx.is_connected(undiBetterGraph)\n",
    "if connected:\n",
    "    print(\"The graph IS connected\")\n",
    "else:\n",
    "    print(\"The graph IS NOT connected\")\n",
    "\n",
    "# Is graph bipartite?\n",
    "bipartite = nx.is_bipartite(undiBetterGraph)\n",
    "if bipartite:\n",
    "    print(\"The graph IS bipartite\")\n",
    "else:\n",
    "    print(\"The graph IS NOT bipartite\")\n",
    "\n",
    "# Center\n",
    "center = nx.center(undiBetterGraph)\n",
    "string = \"\"\n",
    "string += (\"Center of the graph is \" + str(center) + \" ---> [\")\n",
    "for id in center:\n",
    "    string += (undiBetterGraph.nodes[id][\"screen_name\"] + \", \")\n",
    "string = string[0:-2]\n",
    "string += \"]\"\n",
    "print(string)\n",
    "\n",
    "# Diameter\n",
    "diameter = nx.diameter(undiBetterGraph)\n",
    "print(f\"Diameter = {diameter}\")\n",
    "\n",
    "# Radius\n",
    "radius = nx.radius(undiBetterGraph)\n",
    "print(f\"Radius = {radius}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Back to the directed graph we computed some properties and pasted into the node description\n",
    "bt_centrality = nx.betweenness_centrality(undiBetterGraph)\n",
    "print(f\"Betweenness centrality:\")\n",
    "for key, value in bt_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "cl_centrality = nx.closeness_centrality(undiBetterGraph)\n",
    "print(f\"\\n\\nCloseness centrality:\")\n",
    "for key, value in cl_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "dg_centrality = nx.degree_centrality(undiBetterGraph)\n",
    "print(f\"\\n\\nDegree centrality:\")\n",
    "for key, value in dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "# Passing to the previously created directed graph is possible to calculate some more properties\n",
    "in_dg_centrality = nx.in_degree_centrality(betterGraph)\n",
    "print(f\"\\n\\nIn-degree centrality:\")\n",
    "for key, value in in_dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "out_dg_centrality = nx.out_degree_centrality(betterGraph)\n",
    "print(f\"\\n\\nOut-degree centrality:\")\n",
    "for key, value in out_dg_centrality.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "pageRank = nx.pagerank(betterGraph)\n",
    "print(f\"\\n\\nPage Rank:\")\n",
    "for key, value in pageRank.items():\n",
    "    if value != 0:\n",
    "        print(f\"\\t{key}: {value}\")\n",
    "\n",
    "hits = nx.hits(betterGraph, max_iter=500)\n",
    "print(\"HITS:\")\n",
    "for node, authValue in hits[0].items():\n",
    "    print(f\"\\n\\t{node}\\n\\t\\tauth = {authValue}\\n\\t\\t hub = {hits[1][node]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "betterGraphPlot = plotGraph(\"graph/better_networkx.pkl\", True)\n",
    "for id in betterGraph.nodes():\n",
    "    node = betterGraph.nodes[id]\n",
    "    node['in_dg_centrality'] = in_dg_centrality[id]\n",
    "    node['out_dg_centrality'] = out_dg_centrality[id]\n",
    "    node['pageRank'] = pageRank[id]\n",
    "    node['hits_auth'] = hits[0][id]\n",
    "    node['hits_hub'] = hits[1][id]\n",
    "    for index, value in enumerate(betterGraphPlot.node_ids):\n",
    "        if  value == id:\n",
    "            break\n",
    "    plotNode = betterGraphPlot.nodes[index]\n",
    "    plotNode['in_dg_centrality'] = in_dg_centrality[id]\n",
    "    plotNode['out_dg_centrality'] = out_dg_centrality[id]\n",
    "    plotNode['pageRank'] = pageRank[id]\n",
    "    plotNode['hits_auth'] = hits[0][id]\n",
    "    plotNode['hits_hub'] = hits[1][id]\n",
    "    info = plotNode['title']\n",
    "    toAppend = \"<br>In-degree centrality: \" + str(plotNode['in_dg_centrality']) + \"<br>Out-degree centrality: \" + str(plotNode['out_dg_centrality']) + \"<br>PageRank: \" + str(plotNode['pageRank']) + \"<br>HITS_Auth: \" + str(plotNode['hits_auth']) + \"<br>HITS_Hub: \" + str(plotNode['hits_hub'])\n",
    "    info += toAppend\n",
    "    plotNode['title'] = info\n",
    "betterGraphPlot.save_graph(\"graph/betterGraph.html\")\n",
    "print('Added in-degree centrality, out-degree centrality, PageRank and HITS for each node in the directed graph')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}